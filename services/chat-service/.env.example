# ============================================================
# Chat Service Configuration
# ============================================================

# RabbitMQ Settings
QUEUE_HOST=localhost
QUEUE_PORT=5672
INPUT_QUEUE=processed_comments
OUTPUT_QUEUE=chat_responses

RABBITMQ_USER=admin
RABBITMQ_PASSWORD=admin123
RABBITMQ_VHOST=/

# ============================================================
# LLM Configuration
# ============================================================
# Provider: openai, ollama, groq, gemini, huggingface
# Recommended FREE options:
#   - ollama (local, no API key needed)
#   - groq (free API key, fast Llama models)

# === OPTION 1: Ollama (Local, FREE, No API key) ===
# Download: https://ollama.com
# Run: ollama pull llama3.2
LLM_PROVIDER=groq
LLM_MODEL=llama-3.3-70b-versatile
LLM_API_KEY=
# === OPTION 2: Groq (FREE API, Fast) ===
# Get free key: https://console.groq.com/keys
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile
# LLM_API_KEY=gsk_your_groq_api_key_here

# === OPTION 3: OpenAI (Paid) ===
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-3.5-turbo
# LLM_API_KEY=sk-your_openai_key

# === OPTION 4: Google Gemini (Free tier) ===
# Get key: https://makersuite.google.com/app/apikey
# LLM_PROVIDER=gemini
# LLM_MODEL=gemini-pro
# LLM_API_KEY=your_gemini_key

# ============================================================
# Response Settings
# ============================================================
MAX_RESPONSE_LENGTH=150
RESPONSE_TIMEOUT=10.0

# ============================================================
# Persona Settings
# ============================================================
PERSONA_NAME=Chi Chi
PERSONA_STYLE=friendly

# ============================================================
# Debug
# ============================================================
DEBUG=true
